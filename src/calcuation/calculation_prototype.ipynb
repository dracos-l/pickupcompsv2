{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing (2)\n",
    "- Ast percentage\n",
    "- Tov percentage\n",
    "\n",
    "Rebounding (2)\n",
    "- DREB\n",
    "- OREB\n",
    "\n",
    "Scoring Location (8)\n",
    "- Above the break efficiency/volume\n",
    "- Corner efficiency/volume\n",
    "- Midrange efficiency/volume\n",
    "- Paint efficiency/volume\n",
    "\n",
    "Scoring Difficulty (4)\n",
    "- Tight efficiency/volume\n",
    "- Open efficiency/volume\n",
    "\n",
    "Scoring Type (4)\n",
    "- Catch and Shoot efficiency/volume\n",
    "- Pull Up efficiency/volume\n",
    "\n",
    "Defense (4)\n",
    "- Paint Volume/Deterrence\n",
    "- Perimeter Volume/Deterrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offense\n",
    "- Scoring (16) -> 1 = (12)\n",
    "    - Location (8) * 0.5 = 4\n",
    "    - Difficulty (4)\n",
    "    - Type (4)\n",
    "- Playmaking (2) -> 3.25 = 6.5\n",
    "    - Ast \n",
    "    - Tov\n",
    "- OREB (1) -> 1 = 1\n",
    "\n",
    "Defense\n",
    "- Paint (2) -> 4.25 = 8.5\n",
    "- Perimeter (2) -> 4.25 = 8.5\n",
    "- DREB (1) -> 2.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method\n",
    "- Get the absolute distance for each stat in each sub2 category \n",
    "- Get the average for the category type\n",
    "- Multiply that average by the weight\n",
    "- Add up all of the category types and then divide by 25.7 to get main category\n",
    "- Add up both main categories and then divide by 2 and multiple by 100\n",
    "\n",
    "Ex. \n",
    "Scoring = ((Location + Location + Location + Location + Location + Location + Location + Location)/2 + Difficulty + Difficulty + Difficulty + Difficulty + Type + Type + Type + Type)/12\n",
    "Playmaking = (Ast + Tov)/2 \n",
    "OREB = (OREB)/1\n",
    "\n",
    "Offense = ((Scoring * 12) + (Playmaking * 6.5) + (OREB * 1))/19.5\n",
    "\n",
    "Overall = (Offense + Defense)/2\n",
    "\n",
    "Stats:\n",
    "- Smallest Percentage Differnece (unweighted)\n",
    "- Smallest Main Category Difference (unweighted)\n",
    "- Largest Percentage Difference (unweighted)\n",
    "- Largest Main Category Difference (unweighted)\n",
    "- Offense Average Difference (weighted)\n",
    "- Defense Average Difference (weighted)\n",
    "\n",
    "Notes \n",
    "- Scoring can be a list so you can get largest and smallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethan's Answer\n",
    "\n",
    "Paint: 20, 30 \n",
    "Midrange: 40, 30 \n",
    "Corner: 30, 30\n",
    "Above: 100, 70\n",
    "Tight: 20, 30\n",
    "Open: 80, 50\n",
    "Catch: 80, 70\n",
    "Pull: 20, 30\n",
    "Paint D: 40, 30\n",
    "Perimeter D: 80, 50\n",
    "Playmaking: 40, 70\n",
    "Rebounding: 50, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player 1': ('Jaden McDaniels', 0.1598056891025641),\n",
       " 'Player 2': ('Patrick Williams', 0.1871619591346154),\n",
       " 'Player 3': ('Andrew Nembhard', 0.1874198717948718),\n",
       " 'Player 4': ('RJ Barrett', 0.1877854567307692),\n",
       " 'Player 5': ('Jrue Holiday', 0.19259064503205128),\n",
       " 'Player 6': ('David Roddy', 0.19338942307692308),\n",
       " 'Player 7': ('Torrey Craig', 0.19543519631410255),\n",
       " 'Player 8': ('Harrison Barnes', 0.19817958733974356),\n",
       " 'Player 9': ('Jeff Green', 0.19846254006410258),\n",
       " 'Player 10': ('Talen Horton-Tucker', 0.19863030849358973)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "df = pd.read_csv('../data/player_data.csv')\n",
    "\n",
    "my_dict = {'AST_PCT_percentile': 0.4, \n",
    "           'DREB_PCT_percentile' : 0.3,\n",
    "           'OREB_PCT_percentile' : 0.5, \n",
    "           'TOV_PCT_percentile' : 0.7,\n",
    "           'Midrange_volume_pm_percentile' : 0.4, \n",
    "           'Midrange_efficiency_percentile' : 0.3,\n",
    "           'Paint_volume_pm_percentile' : 0.2, \n",
    "           'Paint_efficiency_percentile': 0.3,\n",
    "           'Corner_volume_pm_percentile': 0.3, \n",
    "           'Corner_efficiency_percentile': 0.3,\n",
    "           'Above_the_break_volume_pm_percentile': 1,\n",
    "           'Above_the_break_efficiency_percentile': 0.7, \n",
    "           'Tight_volume_pm_percentile': 0.2,\n",
    "           'Tight_efficiency_percentile': 0.3, \n",
    "           'Open_volume_pm_percentile': 0.8,\n",
    "           'Open_efficiency_percentile': 0.5, \n",
    "           'Catch_and_Shoot_Volume_percentile': 0.8,\n",
    "           'Catch_and_Shoot_Efficiency_percentile': 0.7, \n",
    "           'Pull_up_Volume_percentile': 0.2,\n",
    "           'Pull_up_Efficiency_percentile': 0.3, \n",
    "           'Paint_defense_volume_pm_percentile': 0.4,\n",
    "           'Paint_defense_deterance_percentile': 0.3,\n",
    "           'Perimeter_defense_volume_pm_percentile': 0.8,\n",
    "           'Perimeter_defense_deterance_percentile': 0.5}\n",
    "\n",
    "\n",
    "def calculation(person_dict, players_df):\n",
    "    similarity_dic = {}\n",
    "    \n",
    "    for ___ , player_df in players_df.iterrows():\n",
    "        Scoring = (((abs(person_dict['Paint_volume_pm_percentile'] - player_df['Paint_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Paint_efficiency_percentile'] - player_df['Paint_efficiency_percentile']) + \n",
    "                   abs(person_dict['Midrange_volume_pm_percentile'] - player_df['Midrange_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Midrange_volume_pm_percentile'] - player_df['Midrange_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Corner_volume_pm_percentile'] - player_df['Corner_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Corner_efficiency_percentile'] - player_df['Corner_efficiency_percentile']) + \n",
    "                   abs(person_dict['Above_the_break_volume_pm_percentile'] - player_df['Above_the_break_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Above_the_break_efficiency_percentile'] - player_df['Above_the_break_efficiency_percentile'])\n",
    "                   )/2) + (abs(person_dict['Tight_efficiency_percentile'] - player_df['Tight_efficiency_percentile']) + \n",
    "                   abs(person_dict['Tight_volume_pm_percentile'] - player_df['Tight_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Open_volume_pm_percentile'] - player_df['Open_volume_pm_percentile']) + \n",
    "                   abs(person_dict['Open_efficiency_percentile'] - player_df['Open_efficiency_percentile'])) \n",
    "                   + (abs(person_dict['Catch_and_Shoot_Efficiency_percentile'] - player_df['Catch_and_Shoot_Efficiency_percentile']) + \n",
    "                   abs(person_dict['Catch_and_Shoot_Volume_percentile'] - player_df['Catch_and_Shoot_Volume_percentile']) + \n",
    "                   abs(person_dict['Pull_up_Volume_percentile'] - player_df['Pull_up_Volume_percentile']) + \n",
    "                   abs(person_dict['Pull_up_Efficiency_percentile'] - player_df['Pull_up_Efficiency_percentile'])))/12\n",
    "        Playmaking = (abs(person_dict['AST_PCT_percentile'] - player_df['AST_PCT_percentile']) + abs(person_dict['TOV_PCT_percentile'] - player_df['TOV_PCT_percentile']))/2\n",
    "        Oreb = (abs(person_dict['OREB_PCT_percentile'] - player_df['OREB_PCT_percentile']))\n",
    "        \n",
    "        Paint = (abs(person_dict['Paint_defense_deterance_percentile'] - player_df['Paint_defense_deterance_percentile']) + abs(person_dict['Paint_defense_volume_pm_percentile'] - player_df['Paint_defense_volume_pm_percentile']))/2\n",
    "        Perimeter = (abs(person_dict['Perimeter_defense_deterance_percentile'] - player_df['Perimeter_defense_deterance_percentile']) + abs(person_dict['Perimeter_defense_volume_pm_percentile'] - player_df['Perimeter_defense_volume_pm_percentile']))/2\n",
    "        Dreb = (abs(person_dict['DREB_PCT_percentile'] - player_df['DREB_PCT_percentile']))\n",
    "\n",
    "        Offense = ((Scoring * 12) + (Playmaking * 6.5) + Oreb)/19.5\n",
    "        Defense = ((Paint * 8.5) + (Perimeter * 8.5) + (Dreb * 2.5))/19.5\n",
    "\n",
    "        player_stats = {'Similarity Score': (Offense + Defense)/2, 'Scoring': Scoring, 'Playmaking': Playmaking, 'Oreb': Oreb, 'Paint': Paint, 'Perimeter': Perimeter, 'Dreb': Dreb, 'Offense': Offense, 'Defense': Defense}\n",
    "\n",
    "        similarity_dic[(player_df['first_name'] + ' ' + player_df['last_name'])] = player_stats\n",
    "        \n",
    "    return similarity_dic\n",
    "    \n",
    "def results(similarity_dic):\n",
    "    dic = {}\n",
    "    counter = 1\n",
    "    similarity10 = sorted(similarity_dic.items(), key=lambda x: x[1]['Similarity Score'], reverse=False)[1:11]\n",
    "    for i in similarity10:\n",
    "        tup = (i[0], i[1]['Similarity Score'])\n",
    "        dic['Player ' + str(counter)] = tup\n",
    "        counter += 1\n",
    "    return dic\n",
    "\n",
    "def highlights(similarity_dic):\n",
    "    dic = {}\n",
    "    similarity1 = sorted(similarity_dic.items(), key=lambda x: x[1]['Similarity Score'], reverse=False)[0]\n",
    "    dic['Offense_value'] = similarity1[1]['Offense']\n",
    "    dic['Defense_value'] = similarity1[1]['Defense']\n",
    "    similarity1[1].pop('Offense') \n",
    "    similarity1[1].pop('Defense')\n",
    "    key_of_min_value = min(similarity1[1], key=similarity1[1].get)\n",
    "    key_of_max_value = max(similarity1[1], key=similarity1[1].get)\n",
    "    dic['Min_value'] = (key_of_min_value, similarity1[1][key_of_min_value])\n",
    "    dic['Max_value'] = (key_of_max_value, similarity1[1][key_of_max_value])\n",
    "\n",
    "    return dic\n",
    "\n",
    "results(calculation(my_dict, df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
