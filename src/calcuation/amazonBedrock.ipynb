{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I delved into the depths of my play style, I discovered that I was most similar to Kristaps Porzingis in certain areas, and least similar in others. On the offensive end, I was thrilled to find that my scoring game was a whopping 70.43% similar to Porzingis's, ranking 15th overall. It seemed that we shared a similar approach to putting the ball in the basket, with a keen eye for opportunity and a knack for converting chances. However, my playmaking skills were a different story, with a mere 32.13% similarity, ranking 202nd overall. It seemed that I relied more on my own scoring prowess rather than setting up teammates for easy baskets.\n",
      "\n",
      "On the defensive end, I was delighted to find that my paint defense was an astonishing 93.65% similar to Porzingis's, ranking 9th overall. It appeared that we shared a similar tenacious approach to defending the paint, with a keen sense of timing and positioning. My perimeter defense was also quite similar, with a 77.05% similarity, ranking 28th overall. However, my defensive rebounding skills were a bit of a mixed bag, with an 83.01% similarity, ranking 44th overall. It seemed that while I was decent at securing rebounds, I wasn't quite as effective as Porzingis in this regard.\n",
      "\n",
      "Overall, I was thrilled to discover that I was a staggering 72.38% similar to Kristaps Porzingis, making me a formidable opponent on the court. While there were areas where I lagged behind, I was proud to find that my scoring and paint defense were among the most similar aspects of my game to Porzingis's. With this knowledge, I was eager to refine my skills and become an even more dominant force on the court.\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt to Meta Llama 3 and print the response.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Llama 3 8B Instruct.\n",
    "model_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "\n",
    "# Define the user message to send.\n",
    "user_message = \"\"\" \n",
    "Kristaps Porzingis\n",
    ": \n",
    "Defense score\n",
    ": \n",
    "0.15018503289473684\n",
    "Defense_rank\n",
    ": \n",
    "4\n",
    "Defensive Rebounding score\n",
    ": \n",
    "0.169921875\n",
    "Defensive Rebounding_rank\n",
    ": \n",
    "44\n",
    "Offense score\n",
    ": \n",
    "0.40222328587582235\n",
    "Offense_rank\n",
    ": \n",
    "33\n",
    "Offensive Rebounding score\n",
    ": \n",
    "0.212890625\n",
    "Offensive Rebounding_rank\n",
    ": \n",
    "55\n",
    "Paint Defense score\n",
    ": \n",
    "0.0634765625\n",
    "Paint Defense_rank\n",
    ": \n",
    "9\n",
    "Perimeter Defense score\n",
    ": \n",
    "0.2294921875\n",
    "Perimeter Defense_rank\n",
    ": \n",
    "28\n",
    "Playmaking score\n",
    ": \n",
    "0.6787109375\n",
    "Playmaking_rank\n",
    ": \n",
    "202\n",
    "Scoring score\n",
    ": \n",
    "0.29571533203125\n",
    "Scoring_rank\n",
    ": \n",
    "15\n",
    "Similarity Score\n",
    ": \n",
    "0.2762041593852796\n",
    "Similarity Score_rank\n",
    ": \n",
    "1\n",
    "This is a dictionary of the player I got that was most similar to my play style. Scores signify how different my game in a particular area is from the NBA player I matched with.\n",
    "Rank signifies how similar that area is to the NBA player I matched with. The lower the rank, the more similar I am to the NBA player in that area. Higher and lower scores or rank are just about distance from my play style; higher or lower scores or rank don't say anything about the quality of my play style. \n",
    "Tell a story about the places I am most similar to and least similar to the NBA player I matched with. And example paragraph is below When looking at offense, Kristaps Porzingis's scoring game was 70.43% similar and the 15th most similar overall to yours. Playmaking was 32.13% similar and the 202nd most similar overall. Lastly, offensive rebounding was 78.71% similar and the 55th most similar overall. On to your defense, Kristaps Porzingis's paint defense was 93.65% similar and the 9th most similar overall to yours. Perimeter defense was 77.05% similar and the 28th most similar overall. And finally, defensive rebounding was 83.01% similar and the 44th similar overall. Overall, we calculated that you were 72.38% similar to Kristaps Porzingis.\n",
    "\"\"\"\n",
    "\n",
    "# Embed the message in Llama 3's prompt format.\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{user_message}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "request = {\n",
    "    \"prompt\": prompt,\n",
    "    # Optional inference parameters:\n",
    "    \"max_gen_len\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "# Encode and send the request.\n",
    "response = client.invoke_model(body=json.dumps(request), modelId=model_id)\n",
    "\n",
    "# Decode the native response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the generated text.\n",
    "response_text = model_response[\"generation\"]\n",
    "print(response_text)\n",
    "\n",
    "# Learn more about the Llama 3 prompt format in the documentation:\n",
    "# https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/#special-tokens-used-with-meta-llama-3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BedrockRuntime' object has no attribute 'invoke_jurassic2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/edubs5/Desktop/Pickup_Basketball_Comp/pickupcompsv2/src/calcuation/amazonBedrock.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/edubs5/Desktop/Pickup_Basketball_Comp/pickupcompsv2/src/calcuation/amazonBedrock.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     completion \u001b[39m=\u001b[39m response_body[\u001b[39m\"\u001b[39m\u001b[39mcompletions\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edubs5/Desktop/Pickup_Basketball_Comp/pickupcompsv2/src/calcuation/amazonBedrock.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m completion\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/edubs5/Desktop/Pickup_Basketball_Comp/pickupcompsv2/src/calcuation/amazonBedrock.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m client\u001b[39m.\u001b[39;49minvoke_jurassic2(user_message)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/botocore/client.py:918\u001b[0m, in \u001b[0;36mBaseClient.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[39mif\u001b[39;00m event_response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m event_response\n\u001b[0;32m--> 918\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    919\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BedrockRuntime' object has no attribute 'invoke_jurassic2'"
     ]
    }
   ],
   "source": [
    "def invoke_jurassic2(self, prompt):\n",
    "\n",
    "    body = {\"prompt\": prompt, \"temperature\": 0.5, \"maxTokens\": 200}\n",
    "\n",
    "    response = self.bedrock_runtime_client.invoke_model(modelId=\"ai21.j2-mid-v1\", body=json.dumps(body) )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    completion = response_body[\"completions\"][0][\"data\"][\"text\"]\n",
    "\n",
    "    return completion\n",
    "\n",
    "client.invoke_jurassic2(user_message)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
